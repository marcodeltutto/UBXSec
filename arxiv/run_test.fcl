#include "services_microboone.fcl"

process_name: cosmicflashtagger 

services:
{
  scheduler:               { defaultExceptions: false }    # Make all uncaught exceptions fatal.
  # Load the service that manages root files for histograms.
  TFileService: { fileName: "acpttagger.root" }
  TimeTracker:             @local::microboone_time_tracker
  MemoryTracker:           @local::microboone_memory_tracker
  RandomNumberGenerator:   {} #ART native random number generator                                                                                          
  message:                 @local::microboone_message_services_prod_debug
  FileCatalogMetadata:     @local::art_file_catalog_mc
  @table::microboone_simulation_services
}

services.DetectorPropertiesService.NumberTimeSamples:        6400
services.DetectorPropertiesService.ReadOutWindowSize:        6400
services.DetectorClocksService.InheritClockConfig:           false
services.DetectorClocksService.TriggerOffsetTPC:             -0.400e3
services.DetectorClocksService.TrigModuleName:               "daq"

services.Geometry.ForceUseFCLOnly: true

services.TimeTracker.printSummary: false
services.TimeTracker.dbOutput: {}

services.MemoryTracker.printSummaries: []
services.MemoryTracker.includeMallocInfo: false
services.MemoryTracker.dbOutput.filename: ""

#source is now a root file
source:
{
  module_type: RootInput
  maxEvents:   -1        # Number of events to create
  inputCommands: ["keep *_*_*_*", "drop raw::OpDetWaveforms_DataApr2016RecoStage1_saturation_*"]
}

# Define and configure some modules to do work on each event.
# First modules are defined; they are scheduled later.
# Modules are grouped by type.
physics:
{

 producers:
 {
 }

 filters: 
 {
   testfilter: { module_type: TestFilter
                 input_param: "optional" }
 }

 analyzers:
 {
    testanalyzer : { module_type: TestAnalyzer
                     input_param: "optional" }
 }

 reco: [ testfilter ]

 #define the output stream, there could be more than one if using filters 
 stream1:  [ out1 ]

 #trigger_paths is a keyword and contains the paths that modify the art::event, 
 #ie filters and producers
 trigger_paths: [reco] 

 #end_paths is a keyword and contains the paths that do not modify the art::Event, 
 #ie analyzers and output streams.  these all run simultaneously
 end_paths:     [stream1]
}

#block to define where the output goes.  if you defined a filter in the physics
#block and put it in the trigger_paths then you need to put a SelectEvents: {SelectEvents: [XXX]}
#entry in the output stream you want those to go to, where XXX is the label of the filter module(s)
outputs:
{
 out1:
 {
   module_type: RootOutput
   fileName:    "output.root"
   dataTier:    "reco"
   compressionLevel: 1
   outputCommands: [ "keep *_*_*_*" ]
   }
}

### Here we include the file giving us run/data dependent overrides

### Here we try to suppress known and pointless messages
services.message.destinations :
{
  STDCOUT: 
  {
     type:      "cout"      #tells the message service to output this destination to cout
     threshold: "WARNING"   #tells the message service that this destination applies to WARNING and higher level messages
     append:     true       #says to append all messages to the output
     categories:
     {
       ChannelFilter:
       {
         limit: 0
         reportEvery: 0
       }
       default:
       {
         limit: -1  #don't print anything at the infomsg level except the explicitly named categories
         reportEvery: 1
       }
     }
  }
}


